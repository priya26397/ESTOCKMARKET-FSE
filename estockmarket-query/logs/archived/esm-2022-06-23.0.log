2022-06-23 15:21:24,027 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:24,000 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:24,000 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:24,123 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:25,027 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:25,027 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:25,815 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:25,826 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,591 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-30, groupId=group_id] Member consumer-group_id-30-e5b87e79-c6de-4da1-9a2b-4b06453d5b2d sending LeaveGroup request to coordinator host.docker.internal:9092 (id: 2147483647 rack: null) due to consumer poll timeout has expired. This means the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time processing messages. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
2022-06-23 15:21:30,596 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62b33f0a52d23d5bec795f97', description='null'}-localhost:27017] Opened connection [connectionId{localValue:13, serverValue:51}] to localhost:27017
2022-06-23 15:21:30,602 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-28-90f7896d-47e8-4030-91a4-35663a2f747e', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,603 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-27-cba831f5-afc5-44d5-9e51-8eb498e3113b', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,605 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-31-f2d3bb23-19bc-4f0a-a6e7-7f24329af2b3', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,633 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,634 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Lost previously assigned partitions updateStock-0
2022-06-23 15:21:30,640 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] group_id: partitions lost: [updateStock-0]
2022-06-23 15:21:30,640 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] group_id: partitions revoked: [updateStock-0]
2022-06-23 15:21:30,642 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,653 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,654 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,655 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,656 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,691 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-26-2590e4a3-5f48-48a1-bfc6-cda6f6c02279', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,691 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-25-65c4cb74-1231-47c4-a9d4-4517148cde0a', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,692 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-32-4eb8a0c6-41ec-4f26-812e-6e1d2a5a510d', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,693 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Attempt to heartbeat with Generation{generationId=64, memberId='consumer-group_id-29-01a9da59-81b2-4aa3-bdde-2428f378c983', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:21:30,756 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,758 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,759 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62b33f0a52d23d5bec795f97', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=6125100}
2022-06-23 15:21:30,759 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,759 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,760 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,761 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,761 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,762 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:21:30,763 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Lost previously assigned partitions removeSector-0
2022-06-23 15:21:30,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Lost previously assigned partitions createUser-0
2022-06-23 15:21:30,779 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] group_id: partitions lost: [removeSector-0]
2022-06-23 15:21:30,780 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] group_id: partitions lost: [createUser-0]
2022-06-23 15:21:30,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Lost previously assigned partitions removeCompany-0
2022-06-23 15:21:30,780 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] group_id: partitions revoked: [removeSector-0]
2022-06-23 15:21:30,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,781 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Lost previously assigned partitions createStock-0
2022-06-23 15:21:30,781 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Lost previously assigned partitions createCompany-0
2022-06-23 15:21:30,780 ERROR org.apache.kafka.clients.consumer.internals.AbstractCoordinator$LeaveGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] LeaveGroup request with Generation{generationId=64, memberId='consumer-group_id-30-e5b87e79-c6de-4da1-9a2b-4b06453d5b2d', protocol='range'} failed with error: The coordinator is not aware of this member.
2022-06-23 15:21:30,781 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions lost: [createStock-0]
2022-06-23 15:21:30,781 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] group_id: partitions lost: [createCompany-0]
2022-06-23 15:21:30,781 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions revoked: [createStock-0]
2022-06-23 15:21:30,782 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,782 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] group_id: partitions revoked: [createCompany-0]
2022-06-23 15:21:30,782 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:21:30,782 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,784 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,790 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Lost previously assigned partitions removeStock-0
2022-06-23 15:21:30,791 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions lost: [removeStock-0]
2022-06-23 15:21:30,791 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Lost previously assigned partitions createSector-0
2022-06-23 15:21:30,791 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] group_id: partitions revoked: [createUser-0]
2022-06-23 15:21:30,791 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] group_id: partitions lost: [createSector-0]
2022-06-23 15:21:30,791 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] group_id: partitions revoked: [createSector-0]
2022-06-23 15:21:30,791 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,792 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,792 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] group_id: partitions lost: [removeCompany-0]
2022-06-23 15:21:30,793 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] group_id: partitions revoked: [removeCompany-0]
2022-06-23 15:21:30,793 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,794 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,795 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,796 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,797 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,799 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions revoked: [removeStock-0]
2022-06-23 15:21:30,799 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,801 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,806 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,811 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully joined group with generation Generation{generationId=66, memberId='consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500', protocol='range'}
2022-06-23 15:21:30,811 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Successfully joined group with generation Generation{generationId=66, memberId='consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae', protocol='range'}
2022-06-23 15:21:30,812 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Successfully joined group with generation Generation{generationId=66, memberId='consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf', protocol='range'}
2022-06-23 15:21:30,815 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Finished assignment for group at generation 66: {consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae=Assignment(partitions=[updateStock-0]), consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500=Assignment(partitions=[createStock-0]), consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf=Assignment(partitions=[createUser-0])}
2022-06-23 15:21:30,816 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,817 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,819 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=66, memberId='consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae', protocol='range'}
2022-06-23 15:21:30,819 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=66, memberId='consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500', protocol='range'}
2022-06-23 15:21:30,819 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Rebalance failed.
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2022-06-23 15:21:30,820 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,820 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Rebalance failed.
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2022-06-23 15:21:30,820 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,821 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] SyncGroup failed: The group began another rebalance. Need to re-join the group. Sent generation was Generation{generationId=66, memberId='consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf', protocol='range'}
2022-06-23 15:21:30,822 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Rebalance failed.
org.apache.kafka.common.errors.RebalanceInProgressException: The group is rebalancing, so a rejoin is needed.
2022-06-23 15:21:30,822 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] (Re-)joining group
2022-06-23 15:21:30,826 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-29-c30a0648-1041-40e6-a201-476887cb6568', protocol='range'}
2022-06-23 15:21:30,827 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae', protocol='range'}
2022-06-23 15:21:30,828 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-28-75224995-a1a2-4742-8aee-7106307dbae7', protocol='range'}
2022-06-23 15:21:30,829 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500', protocol='range'}
2022-06-23 15:21:30,829 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-32-7a6f86da-ac9a-4f11-b8f0-6d3ab522b0e9', protocol='range'}
2022-06-23 15:21:30,830 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-27-ea6f0bdd-b2f4-4d05-adfc-e4061ac642f8', protocol='range'}
2022-06-23 15:21:30,831 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-31-7d0ac8a3-0120-493a-929f-de22340b1dc2', protocol='range'}
2022-06-23 15:21:30,832 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Successfully joined group with generation Generation{generationId=67, memberId='consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf', protocol='range'}
2022-06-23 15:21:30,836 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Finished assignment for group at generation 67: {consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae=Assignment(partitions=[updateStock-0]), consumer-group_id-27-ea6f0bdd-b2f4-4d05-adfc-e4061ac642f8=Assignment(partitions=[removeSector-0]), consumer-group_id-31-7d0ac8a3-0120-493a-929f-de22340b1dc2=Assignment(partitions=[removeCompany-0]), consumer-group_id-28-75224995-a1a2-4742-8aee-7106307dbae7=Assignment(partitions=[createSector-0]), consumer-group_id-32-7a6f86da-ac9a-4f11-b8f0-6d3ab522b0e9=Assignment(partitions=[createCompany-0]), consumer-group_id-29-c30a0648-1041-40e6-a201-476887cb6568=Assignment(partitions=[removeStock-0]), consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500=Assignment(partitions=[createStock-0]), consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf=Assignment(partitions=[createUser-0])}
2022-06-23 15:21:30,844 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae', protocol='range'}
2022-06-23 15:21:30,845 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Notifying assignor about the new Assignment(partitions=[updateStock-0])
2022-06-23 15:21:30,845 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Adding newly assigned partitions: updateStock-0
2022-06-23 15:21:30,847 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-28-75224995-a1a2-4742-8aee-7106307dbae7', protocol='range'}
2022-06-23 15:21:30,847 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-29-c30a0648-1041-40e6-a201-476887cb6568', protocol='range'}
2022-06-23 15:21:30,848 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createSector-0])
2022-06-23 15:21:30,848 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeStock-0])
2022-06-23 15:21:30,848 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Adding newly assigned partitions: createSector-0
2022-06-23 15:21:30,848 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Adding newly assigned partitions: removeStock-0
2022-06-23 15:21:30,849 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500', protocol='range'}
2022-06-23 15:21:30,850 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-32-7a6f86da-ac9a-4f11-b8f0-6d3ab522b0e9', protocol='range'}
2022-06-23 15:21:30,850 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createStock-0])
2022-06-23 15:21:30,851 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createCompany-0])
2022-06-23 15:21:30,851 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-27-ea6f0bdd-b2f4-4d05-adfc-e4061ac642f8', protocol='range'}
2022-06-23 15:21:30,851 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-31-7d0ac8a3-0120-493a-929f-de22340b1dc2', protocol='range'}
2022-06-23 15:21:30,851 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Successfully synced group in generation Generation{generationId=67, memberId='consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf', protocol='range'}
2022-06-23 15:21:30,859 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Adding newly assigned partitions: createStock-0
2022-06-23 15:21:30,859 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeSector-0])
2022-06-23 15:21:30,859 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Adding newly assigned partitions: removeSector-0
2022-06-23 15:21:30,860 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Adding newly assigned partitions: createCompany-0
2022-06-23 15:21:30,861 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeCompany-0])
2022-06-23 15:21:30,861 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createUser-0])
2022-06-23 15:21:30,861 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Adding newly assigned partitions: removeCompany-0
2022-06-23 15:21:30,861 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Adding newly assigned partitions: createUser-0
2022-06-23 15:21:30,863 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Setting offset for partition updateStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,863 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Setting offset for partition createSector-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,866 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Setting offset for partition removeStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,867 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Setting offset for partition createStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,868 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Setting offset for partition removeSector-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,868 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Setting offset for partition createCompany-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,869 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Setting offset for partition removeCompany-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,870 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] group_id: partitions assigned: [updateStock-0]
2022-06-23 15:21:30,870 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions assigned: [removeStock-0]
2022-06-23 15:21:30,870 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] group_id: partitions assigned: [createSector-0]
2022-06-23 15:21:30,871 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions assigned: [createStock-0]
2022-06-23 15:21:30,872 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] group_id: partitions assigned: [createCompany-0]
2022-06-23 15:21:30,872 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] group_id: partitions assigned: [removeSector-0]
2022-06-23 15:21:30,874 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Setting offset for partition createUser-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:21:30,875 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] group_id: partitions assigned: [removeCompany-0]
2022-06-23 15:21:30,876 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] group_id: partitions assigned: [createUser-0]
2022-06-22 23:04:01,977 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62b33f0a52d23d5bec795f97', description='null'}-localhost:27017] Exception in monitor thread while connecting to server localhost:27017
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:630)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:515)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:355)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:315)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:215)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:144)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/java.net.SocketInputStream.socketRead0(Native Method)
	at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:109)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:131)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:647)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:512)
	... 5 common frames omitted
2022-06-22 23:04:01,981 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62b33f0a52d23d5bec795f97', description='null'}-localhost:27017] Opened connection [connectionId{localValue:14, serverValue:52}] to localhost:27017
2022-06-22 23:04:01,982 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62b33f0a52d23d5bec795f97', description='null'}-localhost:27017] Monitor thread successfully connected to server with description ServerDescription{address=localhost:27017, type=STANDALONE, state=CONNECTED, ok=true, minWireVersion=0, maxWireVersion=13, maxDocumentSize=16777216, logicalSessionTimeoutMinutes=30, roundTripTimeNanos=2261700}
2022-06-22 23:04:33,309 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-7] generateotp priya26397@gmail.com
2022-06-22 23:04:33,312 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-7] generate otp priya26397@gmail.com
2022-06-22 23:04:33,344 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-7] Email template SendOtp.html
2022-06-22 23:04:33,344 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-7] load template SendOtp.html
2022-06-22 23:04:33,350 INFO com.estockmarket.query.domain.service.EmailService [http-nio-6093-exec-7] send otp message to ,subject,messagepriya26397@gmail.com
2022-06-22 23:06:09,492 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-22 23:07:11,261 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-10] validate otp email,otppriya26397@gmail.com
2022-06-22 23:07:11,262 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-10] get otp priya26397@gmail.com
2022-06-22 23:07:11,263 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-10] clear otp priya26397@gmail.com
2022-06-22 23:07:14,306 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-8] authenticate user com.estockmarket.query.domain.util.JwtRequest@598f8c2e
2022-06-22 23:07:14,307 INFO com.estockmarket.query.domain.service.UserService [http-nio-6093-exec-8] user authenticatecom.estockmarket.query.domain.util.JwtRequest@598f8c2e
2022-06-22 23:07:14,335 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-6093-exec-8] Closed connection [connectionId{localValue:12, serverValue:50}] to localhost:27017 because there was a socket exception raised on another connection from this pool.
2022-06-22 23:07:14,418 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-6093-exec-8] Opened connection [connectionId{localValue:15, serverValue:53}] to localhost:27017
2022-06-22 23:07:14,547 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-1] get all company details 
2022-06-22 23:07:14,548 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] fetch all company {}
2022-06-22 23:07:14,554 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] convert to company dto com.estockmarket.query.domain.model.Company@7cffa617
2022-06-22 23:07:49,543 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-2] get all company details 
2022-06-22 23:07:49,544 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] fetch all company {}
2022-06-22 23:07:49,546 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] convert to company dto com.estockmarket.query.domain.model.Company@3cd207b5
2022-06-22 23:08:04,769 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-3] get all company details 
2022-06-22 23:08:04,769 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] fetch all company {}
2022-06-22 23:08:04,772 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] convert to company dto com.estockmarket.query.domain.model.Company@60843bce
2022-06-22 23:08:10,000 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-4] get all company details 
2022-06-22 23:08:10,001 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] fetch all company {}
2022-06-22 23:08:10,003 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] convert to company dto com.estockmarket.query.domain.model.Company@200f32dd
2022-06-22 23:08:23,584 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-5] fetch stocks based on code,date C-008
2022-06-22 23:08:23,585 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch company stocks based on code,date C-008
2022-06-22 23:08:23,589 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stock query based on code C-008
2022-06-22 23:08:23,591 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:08:23,592 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stockaggregate based on code,date C-008
2022-06-22 23:08:23,592 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-22 23:09:05,220 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-22 23:09:05,221 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-22 23:09:05,223 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@13826471
2022-06-22 23:09:29,719 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@3c48b81b
2022-06-22 23:09:30,306 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@43b04ac8
2022-06-22 23:09:30,406 ERROR org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Offset commit failed on partition createStock-0 at offset 2: The coordinator is not aware of this member.
2022-06-22 23:09:30,407 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] OffsetCommit failed with Generation{generationId=67, memberId='consumer-group_id-25-4e8b4451-442e-4e18-b761-ea61f514b500', protocol='range'}: The coordinator is not aware of this member.
2022-06-22 23:09:30,413 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Consumer exception
java.lang.IllegalStateException: This error handler cannot process 'org.apache.kafka.clients.consumer.CommitFailedException's; no record information is available
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:200)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.handleConsumerException(KafkaMessageListenerContainer.java:1602)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1210)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.apache.kafka.clients.consumer.CommitFailedException: Commit cannot be completed since the group has already rebalanced and assigned the partitions to another member. This means that the time between subsequent calls to poll() was longer than the configured max.poll.interval.ms, which typically implies that the poll loop is spending too much time message processing. You can address this either by increasing max.poll.interval.ms or by reducing the maximum size of batches returned in poll() with max.poll.records.
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:1256)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator$OffsetCommitResponseHandler.handle(ConsumerCoordinator.java:1163)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1173)
	at org.apache.kafka.clients.consumer.internals.AbstractCoordinator$CoordinatorResponseHandler.onSuccess(AbstractCoordinator.java:1148)
	at org.apache.kafka.clients.consumer.internals.RequestFuture$1.onSuccess(RequestFuture.java:206)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.fireSuccess(RequestFuture.java:169)
	at org.apache.kafka.clients.consumer.internals.RequestFuture.complete(RequestFuture.java:129)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient$RequestFutureCompletionHandler.fireCompletion(ConsumerNetworkClient.java:602)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.firePendingCompletedRequests(ConsumerNetworkClient.java:412)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:297)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:236)
	at org.apache.kafka.clients.consumer.internals.ConsumerNetworkClient.poll(ConsumerNetworkClient.java:215)
	at org.apache.kafka.clients.consumer.internals.ConsumerCoordinator.commitOffsetsSync(ConsumerCoordinator.java:1005)
	at org.apache.kafka.clients.consumer.KafkaConsumer.commitSync(KafkaConsumer.java:1495)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doCommitSync(KafkaMessageListenerContainer.java:2656)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitSync(KafkaMessageListenerContainer.java:2651)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.commitIfNecessary(KafkaMessageListenerContainer.java:2637)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.processCommits(KafkaMessageListenerContainer.java:2451)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1235)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	... 3 common frames omitted
2022-06-22 23:09:30,414 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-22 23:09:30,414 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Lost previously assigned partitions createStock-0
2022-06-22 23:09:30,415 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions lost: [createStock-0]
2022-06-22 23:09:30,415 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions revoked: [createStock-0]
2022-06-22 23:09:30,415 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-22 23:09:30,417 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-22 23:09:30,422 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully joined group with generation Generation{generationId=69, memberId='consumer-group_id-25-52422820-4d38-4d2c-bbea-616f2c229f25', protocol='range'}
2022-06-22 23:09:30,422 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Finished assignment for group at generation 69: {consumer-group_id-25-52422820-4d38-4d2c-bbea-616f2c229f25=Assignment(partitions=[createStock-0])}
2022-06-22 23:09:30,426 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully synced group in generation Generation{generationId=69, memberId='consumer-group_id-25-52422820-4d38-4d2c-bbea-616f2c229f25', protocol='range'}
2022-06-22 23:09:30,426 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createStock-0])
2022-06-22 23:09:30,427 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Adding newly assigned partitions: createStock-0
2022-06-22 23:09:30,429 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Setting offset for partition createStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-22 23:09:30,429 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions assigned: [createStock-0]
2022-06-22 23:09:30,437 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@6cd16b34
2022-06-22 23:09:30,900 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:30,902 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:31,040 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@59327b88
2022-06-22 23:09:31,067 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:31,068 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:31,590 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@30dac113
2022-06-22 23:09:31,617 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:31,617 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:32,133 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@2d00c71c
2022-06-22 23:09:32,161 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:32,161 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:32,682 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@51174344
2022-06-22 23:09:32,710 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:32,710 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:33,169 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-10] get all company details 
2022-06-22 23:09:33,169 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] fetch all company {}
2022-06-22 23:09:33,171 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] convert to company dto com.estockmarket.query.domain.model.Company@2d0d288b
2022-06-22 23:09:33,217 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@1b338cd5
2022-06-22 23:09:33,231 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:33,231 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:33,751 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@7d8704f9
2022-06-22 23:09:33,779 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:33,780 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:34,285 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@56141472
2022-06-22 23:09:34,311 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:34,311 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:34,820 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@3d726097
2022-06-22 23:09:34,846 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 0 for partition createStock-0
2022-06-22 23:09:34,847 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:35,361 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@3aa006c8
2022-06-22 23:09:35,364 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for createStock-0@0
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 24 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:35,366 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:35,878 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@27dcfec8
2022-06-22 23:09:35,905 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:35,905 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:36,421 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@1d702abd
2022-06-22 23:09:36,448 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:36,448 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:36,964 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@490c249f
2022-06-22 23:09:36,984 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:36,985 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:36,998 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:09:36,998 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stockaggregate based on code,date C-008
2022-06-22 23:09:36,998 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-22 23:09:37,001 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-1] fetch stocks based on code,date C-008
2022-06-22 23:09:37,001 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch company stocks based on code,date C-008
2022-06-22 23:09:37,002 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stock query based on code C-008
2022-06-22 23:09:37,498 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@2c27cc1
2022-06-22 23:09:37,519 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:37,520 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 59 common frames omitted
2022-06-22 23:09:38,094 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@70a4e102
2022-06-22 23:09:38,113 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:38,114 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at jdk.internal.reflect.GeneratedMethodAccessor267.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor266.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 56 common frames omitted
2022-06-22 23:09:38,633 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@56bec2ba
2022-06-22 23:09:38,659 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:38,659 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at jdk.internal.reflect.GeneratedMethodAccessor267.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor266.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 56 common frames omitted
2022-06-22 23:09:39,181 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@338616ec
2022-06-22 23:09:39,208 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:39,208 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at jdk.internal.reflect.GeneratedMethodAccessor267.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor266.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 56 common frames omitted
2022-06-22 23:09:39,714 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@6d5c22b5
2022-06-22 23:09:39,742 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:39,743 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at jdk.internal.reflect.GeneratedMethodAccessor267.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor266.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 56 common frames omitted
2022-06-22 23:09:40,261 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@3a2762ed
2022-06-22 23:09:40,290 INFO org.apache.kafka.clients.consumer.KafkaConsumer [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Seeking to offset 1 for partition createStock-0
2022-06-22 23:09:40,291 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Error handler threw an exception
org.springframework.kafka.KafkaException: Seek to current after exception; nested exception is org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.SeekUtils.seekOrRecover(SeekUtils.java:206)
	at org.springframework.kafka.listener.SeekToCurrentErrorHandler.handle(SeekToCurrentErrorHandler.java:112)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeErrorHandler(KafkaMessageListenerContainer.java:2359)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2228)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	... 9 common frames omitted
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at jdk.internal.reflect.GeneratedMethodAccessor267.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor266.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 56 common frames omitted
2022-06-22 23:09:40,800 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@1aacdc01
2022-06-22 23:09:40,802 ERROR org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] Backoff FixedBackOff{interval=0, currentAttempts=10, maxAttempts=9} exhausted for createStock-0@1
org.springframework.kafka.listener.ListenerExecutionFailedException: Listener method 'public void com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(java.lang.String) throws java.lang.Exception' threw exception; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.decorateException(KafkaMessageListenerContainer.java:2371)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2342)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeOnMessage(KafkaMessageListenerContainer.java:2303)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeRecordListener(KafkaMessageListenerContainer.java:2217)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeWithRecords(KafkaMessageListenerContainer.java:2142)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeRecordListener(KafkaMessageListenerContainer.java:2024)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeListener(KafkaMessageListenerContainer.java:1706)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.invokeIfHaveRecords(KafkaMessageListenerContainer.java:1274)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.pollAndInvoke(KafkaMessageListenerContainer.java:1266)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.run(KafkaMessageListenerContainer.java:1161)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: org.springframework.dao.DuplicateKeyException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }; nested exception is com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at org.springframework.data.mongodb.core.MongoExceptionTranslator.translateExceptionIfPossible(MongoExceptionTranslator.java:106)
	at org.springframework.data.mongodb.core.MongoTemplate.potentiallyConvertRuntimeException(MongoTemplate.java:2899)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:555)
	at org.springframework.data.mongodb.core.MongoTemplate.insertDocument(MongoTemplate.java:1458)
	at org.springframework.data.mongodb.core.MongoTemplate.doInsert(MongoTemplate.java:1257)
	at org.springframework.data.mongodb.core.MongoTemplate.insert(MongoTemplate.java:1172)
	at org.springframework.data.mongodb.repository.support.SimpleMongoRepository.save(SimpleMongoRepository.java:91)
	at jdk.internal.reflect.GeneratedMethodAccessor267.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker$RepositoryFragmentMethodInvoker.lambda$new$0(RepositoryMethodInvoker.java:289)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.doInvoke(RepositoryMethodInvoker.java:137)
	at org.springframework.data.repository.core.support.RepositoryMethodInvoker.invoke(RepositoryMethodInvoker.java:121)
	at org.springframework.data.repository.core.support.RepositoryComposition$RepositoryFragments.invoke(RepositoryComposition.java:529)
	at org.springframework.data.repository.core.support.RepositoryComposition.invoke(RepositoryComposition.java:285)
	at org.springframework.data.repository.core.support.RepositoryFactorySupport$ImplementationMethodExecutionInterceptor.invoke(RepositoryFactorySupport.java:599)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.doInvoke(QueryExecutorMethodInterceptor.java:163)
	at org.springframework.data.repository.core.support.QueryExecutorMethodInterceptor.invoke(QueryExecutorMethodInterceptor.java:138)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.data.projection.DefaultMethodInvokingMethodInterceptor.invoke(DefaultMethodInvokingMethodInterceptor.java:80)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:97)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at jdk.internal.reflect.GeneratedMethodAccessor266.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.aop.support.AopUtils.invokeJoinpointUsingReflection(AopUtils.java:344)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.invokeJoinpoint(ReflectiveMethodInvocation.java:198)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163)
	at org.springframework.dao.support.PersistenceExceptionTranslationInterceptor.invoke(PersistenceExceptionTranslationInterceptor.java:137)
	at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186)
	at org.springframework.aop.framework.JdkDynamicAopProxy.invoke(JdkDynamicAopProxy.java:215)
	at com.sun.proxy.$Proxy167.save(Unknown Source)
	at com.estockmarket.query.domain.service.StockService.createStock(StockService.java:99)
	at com.estockmarket.query.infrastructure.eventsourcing.KafkaStocksEventListener.createStock(KafkaStocksEventListener.java:30)
	at jdk.internal.reflect.GeneratedMethodAccessor265.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:171)
	at org.springframework.messaging.handler.invocation.InvocableHandlerMethod.invoke(InvocableHandlerMethod.java:120)
	at org.springframework.kafka.listener.adapter.HandlerAdapter.invoke(HandlerAdapter.java:56)
	at org.springframework.kafka.listener.adapter.MessagingMessageListenerAdapter.invokeHandler(MessagingMessageListenerAdapter.java:347)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:92)
	at org.springframework.kafka.listener.adapter.RecordMessagingMessageListenerAdapter.onMessage(RecordMessagingMessageListenerAdapter.java:53)
	at org.springframework.kafka.listener.KafkaMessageListenerContainer$ListenerConsumer.doInvokeOnMessage(KafkaMessageListenerContainer.java:2322)
	... 11 common frames omitted
Caused by: com.mongodb.MongoWriteException: E11000 duplicate key error collection: estockmarket.stocks index: _id_ dup key: { _id: 23 }
	at com.mongodb.client.internal.MongoCollectionImpl.executeSingleWriteRequest(MongoCollectionImpl.java:1017)
	at com.mongodb.client.internal.MongoCollectionImpl.executeInsertOne(MongoCollectionImpl.java:470)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:453)
	at com.mongodb.client.internal.MongoCollectionImpl.insertOne(MongoCollectionImpl.java:447)
	at org.springframework.data.mongodb.core.MongoTemplate.lambda$insertDocument$16(MongoTemplate.java:1464)
	at org.springframework.data.mongodb.core.MongoTemplate.execute(MongoTemplate.java:553)
	... 56 common frames omitted
2022-06-22 23:09:45,908 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch stocks based on code,date C-008
2022-06-22 23:09:45,909 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch company stocks based on code,date C-008
2022-06-22 23:09:45,908 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:09:45,909 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-22 23:09:45,910 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stockaggregate based on code,date C-008
2022-06-22 23:09:45,910 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-22 23:09:45,989 INFO com.mongodb.diagnostics.logging.SLF4JLogger [http-nio-6093-exec-3] Opened connection [connectionId{localValue:16, serverValue:54}] to localhost:27017
2022-06-22 23:10:49,480 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-6] get all company details 
2022-06-22 23:10:49,481 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-6] fetch all company {}
2022-06-22 23:10:49,484 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-6] convert to company dto com.estockmarket.query.domain.model.Company@2b5ef31f
2022-06-22 23:11:09,495 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-22 23:11:29,315 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-22 23:11:29,315 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-22 23:11:29,319 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@31e3c472
2022-06-22 23:12:48,691 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-28, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,694 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:12:48,695 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,707 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-29, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,708 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-30, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,708 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-31, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,708 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-26, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,708 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-32, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,708 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-27, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,710 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:12:48,710 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:12:48,711 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:12:48,711 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,712 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,712 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,712 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:12:48,712 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:12:48,713 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:48,714 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:12:59,051 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:12:59,051 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stockaggregate based on code,date C-008
2022-06-22 23:12:59,052 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-22 23:12:59,061 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch stocks based on code,date C-008
2022-06-22 23:12:59,061 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch company stocks based on code,date C-008
2022-06-22 23:12:59,062 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-22 23:13:01,327 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-1] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:13:01,328 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stockaggregate based on code,date C-008
2022-06-22 23:13:01,329 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stock query based on code C-008
2022-06-22 23:13:01,339 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch stocks based on code,date C-008
2022-06-22 23:13:01,339 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch company stocks based on code,date C-008
2022-06-22 23:13:01,339 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-22 23:13:15,448 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-4] fetch stocks based on code,date C-008
2022-06-22 23:13:15,449 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch company stocks based on code,date C-008
2022-06-22 23:13:15,450 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch stock query based on code C-008
2022-06-22 23:13:15,450 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:13:15,450 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stockaggregate based on code,date C-008
2022-06-22 23:13:15,451 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-22 23:15:12,130 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-22 23:15:12,131 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-22 23:15:12,133 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@8a812e9
2022-06-22 23:15:15,991 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-9] get all company details 
2022-06-22 23:15:15,992 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] fetch all company {}
2022-06-22 23:15:15,994 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] convert to company dto com.estockmarket.query.domain.model.Company@6f06dfc0
2022-06-22 23:15:27,031 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-10] get all company details 
2022-06-22 23:15:27,032 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] fetch all company {}
2022-06-22 23:15:27,035 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] convert to company dto com.estockmarket.query.domain.model.Company@8204c01
2022-06-22 23:15:40,821 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-8] get all company details 
2022-06-22 23:15:40,822 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-8] fetch all company {}
2022-06-22 23:15:40,824 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-8] convert to company dto com.estockmarket.query.domain.model.Company@60874b94
2022-06-22 23:15:49,856 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-1] get all company details 
2022-06-22 23:15:49,857 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] fetch all company {}
2022-06-22 23:15:49,859 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] convert to company dto com.estockmarket.query.domain.model.Company@14004aa
2022-06-22 23:15:57,767 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:15:57,769 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stockaggregate based on code,date C-008
2022-06-22 23:15:57,769 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-22 23:15:57,770 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-4] fetch stocks based on code,date C-008
2022-06-22 23:15:57,770 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch company stocks based on code,date C-008
2022-06-22 23:15:57,770 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch stock query based on code C-008
2022-06-22 23:16:09,507 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-22 23:16:19,912 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-3] get all company details 
2022-06-22 23:16:19,913 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] fetch all company {}
2022-06-22 23:16:19,915 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] convert to company dto com.estockmarket.query.domain.model.Company@4c3dd0b
2022-06-22 23:16:25,792 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch stocks based on code,date C-008
2022-06-22 23:16:25,793 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch company stocks based on code,date C-008
2022-06-22 23:16:25,793 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-22 23:16:25,792 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-5] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:16:25,794 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stockaggregate based on code,date C-008
2022-06-22 23:16:25,795 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stock query based on code C-008
2022-06-22 23:17:19,573 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-22 23:17:19,574 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-22 23:17:19,577 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@572b5c2f
2022-06-22 23:17:29,894 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch stocks based on code,date C-008
2022-06-22 23:17:29,894 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch company stocks based on code,date C-008
2022-06-22 23:17:29,895 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-22 23:17:29,905 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:17:29,906 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stockaggregate based on code,date C-008
2022-06-22 23:17:29,906 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-22 23:17:48,989 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-1] get all company details 
2022-06-22 23:17:48,991 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] fetch all company {}
2022-06-22 23:17:48,993 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] convert to company dto com.estockmarket.query.domain.model.Company@2b338000
2022-06-22 23:18:09,109 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-4] get all company details 
2022-06-22 23:18:09,110 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] fetch all company {}
2022-06-22 23:18:09,112 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] convert to company dto com.estockmarket.query.domain.model.Company@2ee5a6b7
2022-06-22 23:18:21,363 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-2] get all company details 
2022-06-22 23:18:21,364 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] fetch all company {}
2022-06-22 23:18:21,366 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] convert to company dto com.estockmarket.query.domain.model.Company@5d950bed
2022-06-22 23:18:34,126 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:18:34,126 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stockaggregate based on code,date C-008
2022-06-22 23:18:34,127 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-22 23:18:34,131 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-5] fetch stocks based on code,date C-008
2022-06-22 23:18:34,131 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch company stocks based on code,date C-008
2022-06-22 23:18:34,132 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stock query based on code C-008
2022-06-22 23:18:41,119 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-25, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: coordinator unavailable.isDisconnected: true. Rediscovery will be attempted.
2022-06-22 23:18:41,121 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-22 23:18:46,319 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-22 23:18:46,320 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-22 23:18:46,323 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@5f1506b7
2022-06-22 23:18:59,937 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-9] get all company details 
2022-06-22 23:18:59,938 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] fetch all company {}
2022-06-22 23:18:59,940 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] convert to company dto com.estockmarket.query.domain.model.Company@1b641518
2022-06-22 23:19:15,804 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-10] get all company details 
2022-06-22 23:19:15,805 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] fetch all company {}
2022-06-22 23:19:15,807 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] convert to company dto com.estockmarket.query.domain.model.Company@7efdcc9
2022-06-22 23:19:20,304 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-1] fetch stocks based on code,date C-008
2022-06-22 23:19:20,304 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch company stocks based on code,date C-008
2022-06-22 23:19:20,305 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stock query based on code C-008
2022-06-22 23:19:20,304 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:19:20,306 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stockaggregate based on code,date C-008
2022-06-22 23:19:20,306 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-22 23:20:05,537 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-4] get all company details 
2022-06-22 23:20:05,538 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] fetch all company {}
2022-06-22 23:20:05,540 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] convert to company dto com.estockmarket.query.domain.model.Company@2775d7d
2022-06-22 23:20:16,006 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch min,max and average stock price based on company code,date C-008
2022-06-22 23:20:16,007 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stockaggregate based on code,date C-008
2022-06-22 23:20:16,006 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch stocks based on code,date C-008
2022-06-22 23:20:16,008 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch company stocks based on code,date C-008
2022-06-22 23:20:16,007 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-22 23:20:16,008 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-22 23:21:09,526 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 15:39:58,338 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-25, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 15:39:58,342 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:58,452 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:58,455 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-29-c30a0648-1041-40e6-a201-476887cb6568', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:58,455 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:58,456 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Lost previously assigned partitions removeStock-0
2022-06-23 15:39:58,456 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions lost: [removeStock-0]
2022-06-23 15:39:58,456 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions revoked: [removeStock-0]
2022-06-23 15:39:58,456 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] (Re-)joining group
2022-06-23 15:39:58,459 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] (Re-)joining group
2022-06-23 15:39:58,468 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Successfully joined group with generation Generation{generationId=71, memberId='consumer-group_id-29-bb3edadb-9469-41ab-901b-ded31a73cd48', protocol='range'}
2022-06-23 15:39:58,469 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Finished assignment for group at generation 71: {consumer-group_id-29-bb3edadb-9469-41ab-901b-ded31a73cd48=Assignment(partitions=[removeStock-0])}
2022-06-23 15:39:58,475 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Successfully synced group in generation Generation{generationId=71, memberId='consumer-group_id-29-bb3edadb-9469-41ab-901b-ded31a73cd48', protocol='range'}
2022-06-23 15:39:58,475 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeStock-0])
2022-06-23 15:39:58,475 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Adding newly assigned partitions: removeStock-0
2022-06-23 15:39:58,478 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Setting offset for partition removeStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:39:58,478 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions assigned: [removeStock-0]
2022-06-23 15:39:59,211 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,212 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,212 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,212 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Revoke previously assigned partitions createStock-0
2022-06-23 15:39:59,212 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions revoked: [createStock-0]
2022-06-23 15:39:59,212 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,213 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,213 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Attempt to heartbeat with Generation{generationId=69, memberId='consumer-group_id-25-52422820-4d38-4d2c-bbea-616f2c229f25', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,213 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,214 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$FindCoordinatorResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Discovered group coordinator host.docker.internal:9092 (id: 2147483647 rack: null)
2022-06-23 15:39:59,217 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-32-7a6f86da-ac9a-4f11-b8f0-6d3ab522b0e9', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,218 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] JoinGroup failed: The coordinator is not aware of this member. Need to re-join the group. Sent generation was Generation{generationId=69, memberId='consumer-group_id-25-52422820-4d38-4d2c-bbea-616f2c229f25', protocol='range'}
2022-06-23 15:39:59,235 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:59,236 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Lost previously assigned partitions createCompany-0
2022-06-23 15:39:59,236 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] group_id: partitions lost: [createCompany-0]
2022-06-23 15:39:59,236 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] group_id: partitions revoked: [createCompany-0]
2022-06-23 15:39:59,236 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,256 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,256 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,260 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,260 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-31-7d0ac8a3-0120-493a-929f-de22340b1dc2', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,261 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-28-75224995-a1a2-4742-8aee-7106307dbae7', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,261 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-26-e69d12d1-8541-42cf-968a-a1d16f7a46cf', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,262 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-27-ea6f0bdd-b2f4-4d05-adfc-e4061ac642f8', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,262 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Attempt to heartbeat with Generation{generationId=67, memberId='consumer-group_id-30-537299dd-6e4c-4afa-ac54-4b4796dfbeae', protocol='range'} and group instance id Optional.empty failed due to UNKNOWN_MEMBER_ID, resetting generation
2022-06-23 15:39:59,270 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Rebalance failed.
org.apache.kafka.common.errors.UnknownMemberIdException: The coordinator is not aware of this member.
2022-06-23 15:39:59,270 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:59,270 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,270 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Lost previously assigned partitions removeCompany-0
2022-06-23 15:39:59,270 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:59,271 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] group_id: partitions lost: [removeCompany-0]
2022-06-23 15:39:59,270 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,271 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Lost previously assigned partitions createSector-0
2022-06-23 15:39:59,271 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] group_id: partitions revoked: [removeCompany-0]
2022-06-23 15:39:59,271 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:59,276 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:59,277 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] group_id: partitions lost: [createSector-0]
2022-06-23 15:39:59,277 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Lost previously assigned partitions updateStock-0
2022-06-23 15:39:59,277 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] group_id: partitions revoked: [createSector-0]
2022-06-23 15:39:59,277 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,277 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] group_id: partitions lost: [updateStock-0]
2022-06-23 15:39:59,277 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,276 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Giving away all assigned partitions as lost since generation has been reset,indicating that consumer is no longer part of the group
2022-06-23 15:39:59,277 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,277 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,277 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] group_id: partitions revoked: [updateStock-0]
2022-06-23 15:39:59,278 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Lost previously assigned partitions removeSector-0
2022-06-23 15:39:59,278 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Lost previously assigned partitions createUser-0
2022-06-23 15:39:59,278 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] group_id: partitions lost: [removeSector-0]
2022-06-23 15:39:59,278 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] group_id: partitions revoked: [removeSector-0]
2022-06-23 15:39:59,278 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,278 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] group_id: partitions lost: [createUser-0]
2022-06-23 15:39:59,278 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,278 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] group_id: partitions revoked: [createUser-0]
2022-06-23 15:39:59,278 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,281 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,281 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,281 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,281 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,281 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,282 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,282 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,284 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,295 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,297 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,300 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] (Re-)joining group
2022-06-23 15:39:59,724 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:39:59,725 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,480 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$HeartbeatResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Attempt to heartbeat failed since group is rebalancing
2022-06-23 15:40:01,481 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Revoke previously assigned partitions removeStock-0
2022-06-23 15:40:01,481 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions revoked: [removeStock-0]
2022-06-23 15:40:01,482 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] (Re-)joining group
2022-06-23 15:40:01,485 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-26-99f3951d-c4ff-4cd0-ada6-e8d3928bc842', protocol='range'}
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-25-93ffa8e1-de40-49cf-8f03-d340f1acd539', protocol='range'}
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-30-9b3382db-9efc-4470-ae1d-f81e4b8eb2ae', protocol='range'}
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-28-271752dc-8347-486c-828f-3995611373b9', protocol='range'}
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-31-16e90bdf-f106-4e34-9a0a-430b2f924369', protocol='range'}
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-29-bb3edadb-9469-41ab-901b-ded31a73cd48', protocol='range'}
2022-06-23 15:40:01,487 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,487 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,487 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-27-ec2d4dc8-7736-441c-8dc7-15893f4cceaf', protocol='range'}
2022-06-23 15:40:01,486 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-32-13a9432a-ea42-4e6d-9b20-d5d2bd034a6f', protocol='range'}
2022-06-23 15:40:01,765 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Finished assignment for group at generation 72: {consumer-group_id-25-93ffa8e1-de40-49cf-8f03-d340f1acd539=Assignment(partitions=[createStock-0]), consumer-group_id-31-16e90bdf-f106-4e34-9a0a-430b2f924369=Assignment(partitions=[removeCompany-0]), consumer-group_id-27-ec2d4dc8-7736-441c-8dc7-15893f4cceaf=Assignment(partitions=[removeSector-0]), consumer-group_id-28-271752dc-8347-486c-828f-3995611373b9=Assignment(partitions=[createSector-0]), consumer-group_id-32-13a9432a-ea42-4e6d-9b20-d5d2bd034a6f=Assignment(partitions=[createCompany-0]), consumer-group_id-30-9b3382db-9efc-4470-ae1d-f81e4b8eb2ae=Assignment(partitions=[updateStock-0]), consumer-group_id-29-bb3edadb-9469-41ab-901b-ded31a73cd48=Assignment(partitions=[removeStock-0]), consumer-group_id-26-99f3951d-c4ff-4cd0-ada6-e8d3928bc842=Assignment(partitions=[createUser-0])}
2022-06-23 15:40:01,771 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-26-99f3951d-c4ff-4cd0-ada6-e8d3928bc842', protocol='range'}
2022-06-23 15:40:01,772 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-30-9b3382db-9efc-4470-ae1d-f81e4b8eb2ae', protocol='range'}
2022-06-23 15:40:01,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createUser-0])
2022-06-23 15:40:01,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Notifying assignor about the new Assignment(partitions=[updateStock-0])
2022-06-23 15:40:01,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Adding newly assigned partitions: createUser-0
2022-06-23 15:40:01,772 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Adding newly assigned partitions: updateStock-0
2022-06-23 15:40:01,773 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-29-bb3edadb-9469-41ab-901b-ded31a73cd48', protocol='range'}
2022-06-23 15:40:01,773 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeStock-0])
2022-06-23 15:40:01,773 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Adding newly assigned partitions: removeStock-0
2022-06-23 15:40:01,773 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-25-93ffa8e1-de40-49cf-8f03-d340f1acd539', protocol='range'}
2022-06-23 15:40:01,773 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-28-271752dc-8347-486c-828f-3995611373b9', protocol='range'}
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-31-16e90bdf-f106-4e34-9a0a-430b2f924369', protocol='range'}
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createSector-0])
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-32-13a9432a-ea42-4e6d-9b20-d5d2bd034a6f', protocol='range'}
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-27-ec2d4dc8-7736-441c-8dc7-15893f4cceaf', protocol='range'}
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Requesting to re-join the group and trigger rebalance since the assignment metadata has changed from (version20: {removeCompany=1, createStock=1, createSector=1, removeStock=1, updateStock=1, createUser=1, removeSector=1, createCompany=1}) to (version21: {createStock=1})
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeCompany-0])
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Adding newly assigned partitions: createSector-0
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Adding newly assigned partitions: removeCompany-0
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createCompany-0])
2022-06-23 15:40:01,775 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createStock-0])
2022-06-23 15:40:01,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Adding newly assigned partitions: createCompany-0
2022-06-23 15:40:01,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Adding newly assigned partitions: createStock-0
2022-06-23 15:40:01,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Notifying assignor about the new Assignment(partitions=[removeSector-0])
2022-06-23 15:40:01,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Setting offset for partition createUser-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Setting offset for partition removeStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,776 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Adding newly assigned partitions: removeSector-0
2022-06-23 15:40:01,776 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] group_id: partitions assigned: [createUser-0]
2022-06-23 15:40:01,777 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] group_id: partitions assigned: [removeStock-0]
2022-06-23 15:40:01,777 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Setting offset for partition updateStock-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,777 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] group_id: partitions assigned: [updateStock-0]
2022-06-23 15:40:01,778 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Setting offset for partition createSector-0 to the committed offset FetchPosition{offset=1, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,778 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] group_id: partitions assigned: [createSector-0]
2022-06-23 15:40:01,778 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] [Consumer clientId=consumer-group_id-31, groupId=group_id] Setting offset for partition removeCompany-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,779 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#0-0-C-1] group_id: partitions assigned: [removeCompany-0]
2022-06-23 15:40:01,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Setting offset for partition createStock-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,779 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Setting offset for partition createCompany-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,779 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions assigned: [createStock-0]
2022-06-23 15:40:01,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Revoke previously assigned partitions createStock-0
2022-06-23 15:40:01,780 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] group_id: partitions assigned: [createCompany-0]
2022-06-23 15:40:01,780 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions revoked: [createStock-0]
2022-06-23 15:40:01,780 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] (Re-)joining group
2022-06-23 15:40:01,780 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Setting offset for partition removeSector-0 to the committed offset FetchPosition{offset=0, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,780 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] group_id: partitions assigned: [removeSector-0]
2022-06-23 15:40:01,785 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$JoinGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully joined group with generation Generation{generationId=72, memberId='consumer-group_id-25-93ffa8e1-de40-49cf-8f03-d340f1acd539', protocol='range'}
2022-06-23 15:40:01,789 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator$SyncGroupResponseHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Successfully synced group in generation Generation{generationId=72, memberId='consumer-group_id-25-93ffa8e1-de40-49cf-8f03-d340f1acd539', protocol='range'}
2022-06-23 15:40:01,790 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Notifying assignor about the new Assignment(partitions=[createStock-0])
2022-06-23 15:40:01,790 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Adding newly assigned partitions: createStock-0
2022-06-23 15:40:01,792 INFO org.apache.kafka.clients.consumer.internals.ConsumerCoordinator [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Setting offset for partition createStock-0 to the committed offset FetchPosition{offset=2, offsetEpoch=Optional.empty, currentLeader=LeaderAndEpoch{leader=Optional[host.docker.internal:9092 (id: 0 rack: null)], epoch=0}}
2022-06-23 15:40:01,792 INFO org.springframework.core.log.LogAccessor [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] group_id: partitions assigned: [createStock-0]
2022-06-23 15:44:57,831 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 15:49:58,292 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 15:54:58,329 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 15:59:58,329 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:04:58,339 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:09:58,352 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:14:58,373 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:19:58,363 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:24:58,379 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:29:58,386 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:34:58,380 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:39:58,395 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:44:58,408 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:49:58,413 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:54:58,408 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 16:59:58,413 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:04:58,425 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:09:58,417 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:14:58,428 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:19:58,429 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:24:58,430 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:29:58,431 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:34:58,441 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:39:58,451 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:44:58,454 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:49:58,457 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:54:58,466 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 17:59:58,461 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:04:58,455 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:09:58,461 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:14:58,468 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:19:58,473 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:24:58,477 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:28:58,605 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-23 18:28:58,612 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-23 18:28:58,674 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@2e921cd
2022-06-23 18:29:45,653 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-9] get all company details 
2022-06-23 18:29:45,654 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] fetch all company {}
2022-06-23 18:29:45,656 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] convert to company dto com.estockmarket.query.domain.model.Company@42c5216b
2022-06-23 18:29:54,504 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:29:54,505 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stockaggregate based on code,date C-008
2022-06-23 18:29:54,505 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-23 18:29:54,514 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch stocks based on code,date C-008
2022-06-23 18:29:54,515 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch company stocks based on code,date C-008
2022-06-23 18:29:54,515 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-23 18:29:58,481 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:30:52,442 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-8] get all company details 
2022-06-23 18:30:52,442 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-8] fetch all company {}
2022-06-23 18:30:52,445 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-8] convert to company dto com.estockmarket.query.domain.model.Company@401fa24c
2022-06-23 18:31:10,797 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-2] get all company details 
2022-06-23 18:31:10,798 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] fetch all company {}
2022-06-23 18:31:10,800 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] convert to company dto com.estockmarket.query.domain.model.Company@59311904
2022-06-23 18:31:17,228 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch stocks based on code,date C-008
2022-06-23 18:31:17,229 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch company stocks based on code,date C-008
2022-06-23 18:31:17,229 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-23 18:31:17,231 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:31:17,231 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stockaggregate based on code,date C-008
2022-06-23 18:31:17,231 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-23 18:32:18,495 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-9] get all company details 
2022-06-23 18:32:18,495 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] fetch all company {}
2022-06-23 18:32:18,498 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] convert to company dto com.estockmarket.query.domain.model.Company@4a2ba30b
2022-06-23 18:32:26,397 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-1] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:32:26,398 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stockaggregate based on code,date C-008
2022-06-23 18:32:26,398 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stock query based on code C-008
2022-06-23 18:32:26,410 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch stocks based on code,date C-008
2022-06-23 18:32:26,410 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch company stocks based on code,date C-008
2022-06-23 18:32:26,410 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-23 18:34:34,923 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-2] get all company details 
2022-06-23 18:34:34,924 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] fetch all company {}
2022-06-23 18:34:34,928 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] convert to company dto com.estockmarket.query.domain.model.Company@5eb35430
2022-06-23 18:34:48,742 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:34:48,742 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stockaggregate based on code,date C-008
2022-06-23 18:34:48,743 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-23 18:34:48,745 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch stocks based on code,date C-008
2022-06-23 18:34:48,745 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch company stocks based on code,date C-008
2022-06-23 18:34:48,746 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-23 18:34:58,470 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:36:09,995 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-9] get all company details 
2022-06-23 18:36:09,996 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] fetch all company {}
2022-06-23 18:36:09,998 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] convert to company dto com.estockmarket.query.domain.model.Company@99377f8
2022-06-23 18:37:48,561 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-10] get all company details 
2022-06-23 18:37:48,561 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] fetch all company {}
2022-06-23 18:37:48,564 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-10] convert to company dto com.estockmarket.query.domain.model.Company@7a40e422
2022-06-23 18:38:56,453 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-4] get all company details 
2022-06-23 18:38:56,454 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] fetch all company {}
2022-06-23 18:38:56,457 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] convert to company dto com.estockmarket.query.domain.model.Company@2e8cadba
2022-06-23 18:39:44,574 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-2] get all company details 
2022-06-23 18:39:44,575 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] fetch all company {}
2022-06-23 18:39:44,577 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] convert to company dto com.estockmarket.query.domain.model.Company@f1b9fdb
2022-06-23 18:39:58,472 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:40:04,184 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-3] get all company details 
2022-06-23 18:40:04,185 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] fetch all company {}
2022-06-23 18:40:04,189 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] convert to company dto com.estockmarket.query.domain.model.Company@4c8bae18
2022-06-23 18:40:14,213 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch stocks based on code,date C-008
2022-06-23 18:40:14,214 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch company stocks based on code,date C-008
2022-06-23 18:40:14,215 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-23 18:40:14,227 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-7] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:40:14,228 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch stockaggregate based on code,date C-008
2022-06-23 18:40:14,229 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch stock query based on code C-008
2022-06-23 18:42:47,594 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-1] get all company details 
2022-06-23 18:42:47,595 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] fetch all company {}
2022-06-23 18:42:47,599 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] convert to company dto com.estockmarket.query.domain.model.Company@3d02936b
2022-06-23 18:42:53,444 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch stocks based on code,date C-008
2022-06-23 18:42:53,445 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch company stocks based on code,date C-008
2022-06-23 18:42:53,445 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:42:53,445 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-23 18:42:53,445 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stockaggregate based on code,date C-008
2022-06-23 18:42:53,447 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-23 18:43:53,994 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-3] get all company details 
2022-06-23 18:43:53,995 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] fetch all company {}
2022-06-23 18:43:54,000 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] convert to company dto com.estockmarket.query.domain.model.Company@270a3260
2022-06-23 18:43:57,381 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:43:57,382 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stockaggregate based on code,date C-008
2022-06-23 18:43:57,382 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-23 18:43:57,386 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-7] fetch stocks based on code,date C-008
2022-06-23 18:43:57,387 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch company stocks based on code,date C-008
2022-06-23 18:43:57,387 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch stock query based on code C-008
2022-06-23 18:44:01,245 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-5] fetch stocks based on code,date C-008
2022-06-23 18:44:01,245 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-9] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:44:01,245 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch company stocks based on code,date C-008
2022-06-23 18:44:01,245 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch stockaggregate based on code,date C-008
2022-06-23 18:44:01,246 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch stock query based on code C-008
2022-06-23 18:44:01,246 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stock query based on code C-008
2022-06-23 18:44:58,472 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:49:58,474 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:50:19,598 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch stocks based on code,date C-008
2022-06-23 18:50:19,599 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch company stocks based on code,date C-008
2022-06-23 18:50:19,601 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-6093-exec-10] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.text.ParseException: Unparseable date: "6/22/2022"] with root cause
java.text.ParseException: Unparseable date: "6/22/2022"
	at java.base/java.text.DateFormat.parse(DateFormat.java:395)
	at com.estockmarket.query.domain.service.StockService.getCompanyStocks(StockService.java:50)
	at com.estockmarket.query.application.controller.StockController.getCompanyStocks(StockController.java:39)
	at jdk.internal.reflect.GeneratedMethodAccessor296.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1064)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:228)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:382)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1723)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-06-23 18:50:36,415 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-4] fetch stocks based on code,date C-008
2022-06-23 18:50:36,415 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch company stocks based on code,date C-008
2022-06-23 18:50:36,416 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch stock query based on code C-008
2022-06-23 18:50:57,856 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:50:57,857 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stockaggregate based on code,date C-008
2022-06-23 18:50:57,859 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-23 18:50:57,861 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch stocks based on code,date C-008
2022-06-23 18:50:57,861 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch company stocks based on code,date C-008
2022-06-23 18:50:57,861 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-23 18:51:47,252 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-7] fetch stocks based on code,date C-008
2022-06-23 18:51:47,253 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch company stocks based on code,date C-008
2022-06-23 18:51:47,253 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch stock query based on code C-008
2022-06-23 18:54:58,483 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 18:56:22,465 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-9] get all company details 
2022-06-23 18:56:22,466 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] fetch all company {}
2022-06-23 18:56:22,468 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-9] convert to company dto com.estockmarket.query.domain.model.Company@7f110cf8
2022-06-23 18:56:29,605 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-1] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:56:29,606 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stockaggregate based on code,date C-008
2022-06-23 18:56:29,606 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stock query based on code C-008
2022-06-23 18:56:29,615 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch stocks based on code,date C-008
2022-06-23 18:56:29,615 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch company stocks based on code,date C-008
2022-06-23 18:56:29,615 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-23 18:57:37,708 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-2] get all company details 
2022-06-23 18:57:37,708 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] fetch all company {}
2022-06-23 18:57:37,710 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-2] convert to company dto com.estockmarket.query.domain.model.Company@53d5b2e4
2022-06-23 18:57:45,141 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch min,max and average stock price based on company code,date C-008
2022-06-23 18:57:45,142 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stockaggregate based on code,date C-008
2022-06-23 18:57:45,142 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-23 18:57:45,148 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch stocks based on code,date C-008
2022-06-23 18:57:45,148 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch company stocks based on code,date C-008
2022-06-23 18:57:45,149 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-23 18:58:02,599 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-6] generateotp priya26397@gmail.com
2022-06-23 18:58:02,599 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-6] generate otp priya26397@gmail.com
2022-06-23 18:58:02,599 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-6] Email template SendOtp.html
2022-06-23 18:58:02,600 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-6] load template SendOtp.html
2022-06-23 18:58:02,610 INFO com.estockmarket.query.domain.service.EmailService [http-nio-6093-exec-6] send otp message to ,subject,messagepriya26397@gmail.com
2022-06-23 18:59:39,416 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-1] generateotp priya26397@gmail.com
2022-06-23 18:59:39,417 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-1] generate otp priya26397@gmail.com
2022-06-23 18:59:39,417 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-1] Email template SendOtp.html
2022-06-23 18:59:39,417 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-1] load template SendOtp.html
2022-06-23 18:59:39,418 INFO com.estockmarket.query.domain.service.EmailService [http-nio-6093-exec-1] send otp message to ,subject,messagepriya26397@gmail.com
2022-06-23 18:59:58,485 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:00:12,712 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-8] generateotp priya26397@gmail.com
2022-06-23 19:00:12,713 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-8] generate otp priya26397@gmail.com
2022-06-23 19:00:12,713 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-8] Email template SendOtp.html
2022-06-23 19:00:12,713 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-8] load template SendOtp.html
2022-06-23 19:00:12,714 INFO com.estockmarket.query.domain.service.EmailService [http-nio-6093-exec-8] send otp message to ,subject,messagepriya26397@gmail.com
2022-06-23 19:00:21,393 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-4] generateotp priya26397@gmail.com
2022-06-23 19:00:21,394 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-4] generate otp priya26397@gmail.com
2022-06-23 19:00:21,394 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-4] Email template SendOtp.html
2022-06-23 19:00:21,394 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-4] load template SendOtp.html
2022-06-23 19:00:21,395 INFO com.estockmarket.query.domain.service.EmailService [http-nio-6093-exec-4] send otp message to ,subject,messagepriya26397@gmail.com
2022-06-23 19:01:05,189 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-10] generateotp priya26397@gmail.com
2022-06-23 19:01:05,190 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-10] generate otp priya26397@gmail.com
2022-06-23 19:01:05,190 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-10] Email template SendOtp.html
2022-06-23 19:01:05,190 INFO com.estockmarket.query.domain.service.EmailTemplate [http-nio-6093-exec-10] load template SendOtp.html
2022-06-23 19:01:05,191 INFO com.estockmarket.query.domain.service.EmailService [http-nio-6093-exec-10] send otp message to ,subject,messagepriya26397@gmail.com
2022-06-23 19:01:27,930 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-2] validate otp email,otppriya26397@gmail.com
2022-06-23 19:01:27,930 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-2] get otp priya26397@gmail.com
2022-06-23 19:01:27,931 INFO com.estockmarket.query.domain.service.OTPService [http-nio-6093-exec-2] clear otp priya26397@gmail.com
2022-06-23 19:01:34,377 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-7] authenticate user com.estockmarket.query.domain.util.JwtRequest@485c0b00
2022-06-23 19:01:34,379 INFO com.estockmarket.query.domain.service.UserService [http-nio-6093-exec-7] user authenticatecom.estockmarket.query.domain.util.JwtRequest@485c0b00
2022-06-23 19:01:34,449 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-3] get all company details 
2022-06-23 19:01:34,449 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] fetch all company {}
2022-06-23 19:01:34,451 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] convert to company dto com.estockmarket.query.domain.model.Company@39ea9549
2022-06-23 19:01:39,504 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-6] get all company details 
2022-06-23 19:01:39,505 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-6] fetch all company {}
2022-06-23 19:01:39,506 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-6] convert to company dto com.estockmarket.query.domain.model.Company@6f8d31be
2022-06-23 19:01:47,241 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-5] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:01:47,241 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stockaggregate based on code,date C-008
2022-06-23 19:01:47,242 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stock query based on code C-008
2022-06-23 19:01:47,250 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-9] fetch stocks based on code,date C-008
2022-06-23 19:01:47,250 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch company stocks based on code,date C-008
2022-06-23 19:01:47,251 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch stock query based on code C-008
2022-06-23 19:02:48,629 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-4] get all company details 
2022-06-23 19:02:48,630 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] fetch all company {}
2022-06-23 19:02:48,632 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] convert to company dto com.estockmarket.query.domain.model.Company@44b19e87
2022-06-23 19:02:54,542 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:02:54,543 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stockaggregate based on code,date C-008
2022-06-23 19:02:54,543 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-23 19:02:54,551 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch stocks based on code,date C-008
2022-06-23 19:02:54,551 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch company stocks based on code,date C-008
2022-06-23 19:02:54,552 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-23 19:04:58,493 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:05:04,414 INFO com.estockmarket.query.application.controller.UserController [http-nio-6093-exec-6] authenticate user com.estockmarket.query.domain.util.JwtRequest@7152457a
2022-06-23 19:05:04,414 INFO com.estockmarket.query.domain.service.UserService [http-nio-6093-exec-6] user authenticatecom.estockmarket.query.domain.util.JwtRequest@7152457a
2022-06-23 19:05:19,914 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] remove stocks based on id 24
2022-06-23 19:06:56,950 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-9] fetch stocks based on code,date C-008
2022-06-23 19:06:56,951 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch company stocks based on code,date C-008
2022-06-23 19:06:56,952 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch stock query based on code C-008
2022-06-23 19:07:03,576 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-1] get all company details 
2022-06-23 19:07:03,577 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] fetch all company {}
2022-06-23 19:07:03,579 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-1] convert to company dto com.estockmarket.query.domain.model.Company@41232789
2022-06-23 19:07:09,464 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-8] fetch stocks based on code,date C-008
2022-06-23 19:07:09,464 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch company stocks based on code,date C-008
2022-06-23 19:07:09,465 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-8] fetch stock query based on code C-008
2022-06-23 19:07:09,474 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-4] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:07:09,474 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch stockaggregate based on code,date C-008
2022-06-23 19:07:09,475 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch stock query based on code C-008
2022-06-23 19:08:42,882 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-7] get all company details 
2022-06-23 19:08:42,882 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] fetch all company {}
2022-06-23 19:08:42,885 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-7] convert to company dto com.estockmarket.query.domain.model.Company@51440ddd
2022-06-23 19:08:45,189 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-3] get all company details 
2022-06-23 19:08:45,190 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] fetch all company {}
2022-06-23 19:08:45,192 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-3] convert to company dto com.estockmarket.query.domain.model.Company@aa76a41
2022-06-23 19:08:52,216 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] save stocks com.estockmarket.query.domain.model.Stocks@68dafad6
2022-06-23 19:08:54,376 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-6] get all company details 
2022-06-23 19:08:54,376 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-6] fetch all company {}
2022-06-23 19:08:54,378 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-6] convert to company dto com.estockmarket.query.domain.model.Company@f9197fd
2022-06-23 19:08:56,262 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-5] get all company details 
2022-06-23 19:08:56,263 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-5] fetch all company {}
2022-06-23 19:08:56,264 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-5] convert to company dto com.estockmarket.query.domain.model.Company@21f96f6
2022-06-23 19:09:01,104 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-9] fetch stocks based on code,date C-008
2022-06-23 19:09:01,106 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch company stocks based on code,date C-008
2022-06-23 19:09:01,106 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch stock query based on code C-008
2022-06-23 19:09:01,120 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-1] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:09:01,120 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stockaggregate based on code,date C-008
2022-06-23 19:09:01,121 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-1] fetch stock query based on code C-008
2022-06-23 19:09:08,663 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-8] get all company details 
2022-06-23 19:09:08,664 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-8] fetch all company {}
2022-06-23 19:09:08,665 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-8] convert to company dto com.estockmarket.query.domain.model.Company@13c7d6f3
2022-06-23 19:09:17,297 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-2] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:09:17,297 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-4] fetch stocks based on code,date C-008
2022-06-23 19:09:17,298 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stockaggregate based on code,date C-008
2022-06-23 19:09:17,298 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-2] fetch stock query based on code C-008
2022-06-23 19:09:17,298 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch company stocks based on code,date C-008
2022-06-23 19:09:17,299 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-4] fetch stock query based on code C-008
2022-06-23 19:09:22,749 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-10] fetch stocks based on code,date C-008
2022-06-23 19:09:22,749 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch company stocks based on code,date C-008
2022-06-23 19:09:22,750 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-10] fetch stock query based on code C-008
2022-06-23 19:09:22,766 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-7] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:09:22,766 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch stockaggregate based on code,date C-008
2022-06-23 19:09:22,767 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-7] fetch stock query based on code C-008
2022-06-23 19:09:31,282 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-6] fetch stocks based on code,date C-008
2022-06-23 19:09:31,282 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-3] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:09:31,282 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch company stocks based on code,date C-008
2022-06-23 19:09:31,282 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stockaggregate based on code,date C-008
2022-06-23 19:09:31,283 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-6] fetch stock query based on code C-008
2022-06-23 19:09:31,283 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-3] fetch stock query based on code C-008
2022-06-23 19:09:41,787 INFO com.estockmarket.query.domain.service.StockService [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] remove stocks based on id 25
2022-06-23 19:09:41,850 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-5] fetch min,max and average stock price based on company code,date C-008
2022-06-23 19:09:41,850 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-9] fetch stocks based on code,date C-008
2022-06-23 19:09:41,851 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stockaggregate based on code,date C-008
2022-06-23 19:09:41,851 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch company stocks based on code,date C-008
2022-06-23 19:09:41,851 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-5] fetch stock query based on code C-008
2022-06-23 19:09:41,851 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch stock query based on code C-008
2022-06-23 19:09:58,492 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:13:21,850 INFO com.estockmarket.query.application.controller.CompanyController [http-nio-6093-exec-4] get all company details 
2022-06-23 19:13:21,850 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] fetch all company {}
2022-06-23 19:13:21,853 INFO com.estockmarket.query.domain.service.CompanyService [http-nio-6093-exec-4] convert to company dto com.estockmarket.query.domain.model.Company@32c0ec2e
2022-06-23 19:14:58,490 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:19:58,495 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:24:58,500 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:29:58,500 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:34:58,510 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:39:58,513 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:44:58,515 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:49:58,511 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:51:50,014 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-10] fetch all sector
2022-06-23 19:51:50,014 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-10] fetch all sector {}
2022-06-23 19:51:50,018 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-10] convert to sector Dto com.estockmarket.query.domain.model.Sector@629ef42d
2022-06-23 19:54:58,522 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 19:59:58,524 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:04:58,534 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:05:29,581 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-6] fetch all sector
2022-06-23 20:05:29,582 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-6] fetch all sector {}
2022-06-23 20:05:29,584 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-6] convert to sector Dto com.estockmarket.query.domain.model.Sector@471faae9
2022-06-23 20:09:58,536 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:14:38,608 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-9] fetch all sector
2022-06-23 20:14:38,609 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-9] fetch all sector {}
2022-06-23 20:14:38,612 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-9] convert to sector Dto com.estockmarket.query.domain.model.Sector@3998f63a
2022-06-23 20:14:58,537 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:19:58,542 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:21:36,894 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-1] fetch all sector
2022-06-23 20:21:36,895 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-1] fetch all sector {}
2022-06-23 20:21:36,898 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-1] convert to sector Dto com.estockmarket.query.domain.model.Sector@1f2979d6
2022-06-23 20:23:41,519 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-4] fetch all sector
2022-06-23 20:23:41,520 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-4] fetch all sector {}
2022-06-23 20:23:41,526 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-4] convert to sector Dto com.estockmarket.query.domain.model.Sector@3120a146
2022-06-23 20:24:58,541 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:29:58,538 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:34:58,548 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:39:58,556 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:42:47,847 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-10] fetch all sector
2022-06-23 20:42:47,848 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-10] fetch all sector {}
2022-06-23 20:42:47,850 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-10] convert to sector Dto com.estockmarket.query.domain.model.Sector@15b91cbf
2022-06-23 20:44:58,560 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:49:55,886 INFO com.estockmarket.query.application.controller.SectorController [http-nio-6093-exec-6] fetch all sector
2022-06-23 20:49:55,887 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-6] fetch all sector {}
2022-06-23 20:49:55,890 INFO com.estockmarket.query.domain.service.SectorService [http-nio-6093-exec-6] convert to sector Dto com.estockmarket.query.domain.model.Sector@53b810b4
2022-06-23 20:49:58,568 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:54:58,581 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 20:59:58,593 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:04:58,603 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:09:58,615 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:14:58,622 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:19:58,629 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:24:58,617 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:29:58,604 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:34:58,605 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:39:58,601 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:44:58,604 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:49:58,610 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:54:58,618 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 21:59:58,628 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:04:58,641 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:09:58,653 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:14:58,659 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:19:58,669 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:24:58,671 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:29:58,672 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:34:58,670 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:39:58,668 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:44:58,665 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:49:58,662 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:54:58,662 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 22:59:58,660 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:04:58,671 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:09:58,683 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:14:58,691 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:17:14,610 INFO com.estockmarket.query.application.controller.StockController [http-nio-6093-exec-9] fetch stocks based on code,date code
2022-06-23 23:17:14,615 INFO com.estockmarket.query.domain.service.StockService [http-nio-6093-exec-9] fetch company stocks based on code,date code
2022-06-23 23:17:14,628 ERROR org.apache.juli.logging.DirectJDKLog [http-nio-6093-exec-9] Servlet.service() for servlet [dispatcherServlet] in context with path [] threw exception [Request processing failed; nested exception is java.text.ParseException: Unparseable date: "start"] with root cause
java.text.ParseException: Unparseable date: "start"
	at java.base/java.text.DateFormat.parse(DateFormat.java:395)
	at com.estockmarket.query.domain.service.StockService.getCompanyStocks(StockService.java:50)
	at com.estockmarket.query.application.controller.StockController.getCompanyStocks(StockController.java:39)
	at jdk.internal.reflect.GeneratedMethodAccessor296.invoke(Unknown Source)
	at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.base/java.lang.reflect.Method.invoke(Method.java:566)
	at org.springframework.web.method.support.InvocableHandlerMethod.doInvoke(InvocableHandlerMethod.java:197)
	at org.springframework.web.method.support.InvocableHandlerMethod.invokeForRequest(InvocableHandlerMethod.java:141)
	at org.springframework.web.servlet.mvc.method.annotation.ServletInvocableHandlerMethod.invokeAndHandle(ServletInvocableHandlerMethod.java:106)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.invokeHandlerMethod(RequestMappingHandlerAdapter.java:895)
	at org.springframework.web.servlet.mvc.method.annotation.RequestMappingHandlerAdapter.handleInternal(RequestMappingHandlerAdapter.java:808)
	at org.springframework.web.servlet.mvc.method.AbstractHandlerMethodAdapter.handle(AbstractHandlerMethodAdapter.java:87)
	at org.springframework.web.servlet.DispatcherServlet.doDispatch(DispatcherServlet.java:1064)
	at org.springframework.web.servlet.DispatcherServlet.doService(DispatcherServlet.java:963)
	at org.springframework.web.servlet.FrameworkServlet.processRequest(FrameworkServlet.java:1006)
	at org.springframework.web.servlet.FrameworkServlet.doGet(FrameworkServlet.java:898)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:655)
	at org.springframework.web.servlet.FrameworkServlet.service(FrameworkServlet.java:883)
	at javax.servlet.http.HttpServlet.service(HttpServlet.java:764)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:228)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.apache.tomcat.websocket.server.WsFilter.doFilter(WsFilter.java:53)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.springframework.web.filter.RequestContextFilter.doFilterInternal(RequestContextFilter.java:100)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.springframework.web.filter.FormContentFilter.doFilterInternal(FormContentFilter.java:93)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.springframework.web.filter.CharacterEncodingFilter.doFilterInternal(CharacterEncodingFilter.java:201)
	at org.springframework.web.filter.OncePerRequestFilter.doFilter(OncePerRequestFilter.java:119)
	at org.apache.catalina.core.ApplicationFilterChain.internalDoFilter(ApplicationFilterChain.java:190)
	at org.apache.catalina.core.ApplicationFilterChain.doFilter(ApplicationFilterChain.java:163)
	at org.apache.catalina.core.StandardWrapperValve.invoke(StandardWrapperValve.java:202)
	at org.apache.catalina.core.StandardContextValve.invoke(StandardContextValve.java:97)
	at org.apache.catalina.authenticator.AuthenticatorBase.invoke(AuthenticatorBase.java:542)
	at org.apache.catalina.core.StandardHostValve.invoke(StandardHostValve.java:143)
	at org.apache.catalina.valves.ErrorReportValve.invoke(ErrorReportValve.java:92)
	at org.apache.catalina.core.StandardEngineValve.invoke(StandardEngineValve.java:78)
	at org.apache.catalina.connector.CoyoteAdapter.service(CoyoteAdapter.java:357)
	at org.apache.coyote.http11.Http11Processor.service(Http11Processor.java:382)
	at org.apache.coyote.AbstractProcessorLight.process(AbstractProcessorLight.java:65)
	at org.apache.coyote.AbstractProtocol$ConnectionHandler.process(AbstractProtocol.java:893)
	at org.apache.tomcat.util.net.NioEndpoint$SocketProcessor.doRun(NioEndpoint.java:1723)
	at org.apache.tomcat.util.net.SocketProcessorBase.run(SocketProcessorBase.java:49)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at org.apache.tomcat.util.threads.TaskThread$WrappingRunnable.run(TaskThread.java:61)
	at java.base/java.lang.Thread.run(Thread.java:834)
2022-06-23 23:19:58,702 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:24:58,704 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:29:58,712 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:34:58,727 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:39:58,723 INFO com.netflix.discovery.shared.resolver.aws.ConfigClusterResolver [AsyncResolver-bootstrap-executor-0] Resolving eureka endpoints via configuration
2022-06-23 23:41:53,728 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-27, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:54,064 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-29, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:54,071 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-28, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:54,086 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-32, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:54,091 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-26, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:53,715 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-25, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:53,715 INFO org.apache.kafka.clients.consumer.internals.AbstractCoordinator [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-30, groupId=group_id] Group coordinator host.docker.internal:9092 (id: 2147483647 rack: null) is unavailable or invalid due to cause: session timed out without receiving a heartbeat response.isDisconnected: false. Rediscovery will be attempted.
2022-06-23 23:41:54,083 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#1-0-C-1] [Consumer clientId=consumer-group_id-32, groupId=group_id] Error sending fetch request (sessionId=1453621918, epoch=57685) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:54,069 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#3-0-C-1] [Consumer clientId=consumer-group_id-28, groupId=group_id] Error sending fetch request (sessionId=1164437885, epoch=57683) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:54,089 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#7-0-C-1] [Consumer clientId=consumer-group_id-26, groupId=group_id] Error sending fetch request (sessionId=1080265712, epoch=57684) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:53,708 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#6-0-C-1] [Consumer clientId=consumer-group_id-25, groupId=group_id] Error sending fetch request (sessionId=315498981, epoch=58682) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:53,725 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#2-0-C-1] [Consumer clientId=consumer-group_id-27, groupId=group_id] Error sending fetch request (sessionId=1156360979, epoch=57678) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:53,711 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#5-0-C-1] [Consumer clientId=consumer-group_id-30, groupId=group_id] Error sending fetch request (sessionId=1907469151, epoch=57684) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:54,340 INFO com.mongodb.diagnostics.logging.SLF4JLogger [cluster-ClusterId{value='62b33f0a52d23d5bec795f97', description='null'}-localhost:27017] Exception in monitor thread while connecting to server localhost:27017
com.mongodb.MongoSocketReadTimeoutException: Timeout while receiving message
	at com.mongodb.internal.connection.InternalStreamConnection.translateReadException(InternalStreamConnection.java:630)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:515)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveCommandMessageResponse(InternalStreamConnection.java:355)
	at com.mongodb.internal.connection.InternalStreamConnection.receive(InternalStreamConnection.java:315)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.lookupServerDescription(DefaultServerMonitor.java:215)
	at com.mongodb.internal.connection.DefaultServerMonitor$ServerMonitorRunnable.run(DefaultServerMonitor.java:144)
	at java.base/java.lang.Thread.run(Thread.java:834)
Caused by: java.net.SocketTimeoutException: Read timed out
	at java.base/java.net.SocketInputStream.socketRead0(Native Method)
	at java.base/java.net.SocketInputStream.socketRead(SocketInputStream.java:115)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:168)
	at java.base/java.net.SocketInputStream.read(SocketInputStream.java:140)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:109)
	at com.mongodb.internal.connection.SocketStream.read(SocketStream.java:131)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveResponseBuffers(InternalStreamConnection.java:647)
	at com.mongodb.internal.connection.InternalStreamConnection.receiveMessageWithAdditionalTimeout(InternalStreamConnection.java:512)
	... 5 common frames omitted
2022-06-23 23:41:54,062 INFO org.apache.kafka.clients.FetchSessionHandler [org.springframework.kafka.KafkaListenerEndpointContainer#4-0-C-1] [Consumer clientId=consumer-group_id-29, groupId=group_id] Error sending fetch request (sessionId=192934732, epoch=57688) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
2022-06-23 23:41:54,086 INFO org.apache.kafka.clients.FetchSessionHandler [kafka-coordinator-heartbeat-thread | group_id] [Consumer clientId=consumer-group_id-31, groupId=group_id] Error sending fetch request (sessionId=1770511225, epoch=57684) to node 0:
org.apache.kafka.common.errors.DisconnectException: null
